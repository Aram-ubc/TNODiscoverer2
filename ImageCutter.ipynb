{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sub-images from FITS files\n",
    "\n",
    "**Author:** Aram Lee, Hossen Teimoorinia\n",
    "**Date:** 2025-02-15\n",
    "**File Name:** ImageCutter.ipynb\n",
    "\n",
    "### [Description]\n",
    "This file uses Astropyâ€™s CutOut2D function to process images, whether they contain artificial TNOs or not. It can be used to create a training set with randomized cutout positions and generate sub-images from actual images for applying the trained model.\n",
    "\n",
    "### [Required Libraries]\n",
    "- numpy: 1.26.4\n",
    "- astropy: 6.1.0\n",
    "\n",
    "### [Workflow]  \n",
    "\n",
    "Steps 1-3 are for training the model, and steps 4-6 are for using the model to detect TNOs.\n",
    "\n",
    "|Step|File|Input|Output|Purpose|\n",
    "|-|-|-|-|-|\n",
    "|1|ImageCutter.ipynb **(Here)**|.fits (with artificial moving objects), .plantlist (artificial objects info)| .npy|Extract sub-images for training|\n",
    "|2|Concatenator.ipynb|.npy (sub-images from ImageCutter)|.npy|Prepare dataset for training|\n",
    "|3|Trainer.ipynb|.npy (dataset from Concatenator), .npy (target information)|.h5 (trained CNN models)|Train the model|\n",
    "|-|-|-|-|-|\n",
    "|4|ImageCutter.ipynb **(Here)**|.fits (without artificial moving objects)|.npy|Extract sub-images for detection|\n",
    "|5|Predictor.ipynb|.npy (sub-images from ImageCutter), .npy (target info), .h5 (model)|.npy|Apply trained model to detect objects|\n",
    "|6a|Link_sources_to_objects.py|.npy (classification and regression output from Predictor)|.npy|Detect moving objects (linear fitting method)|\n",
    "|6b|CandidateFinder.ipynb|.npy (classification output from Predictor), .npy (sub-images, target info)|.csv|Detect moving objects (scoring method)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.nddata.utils import Cutout2D \n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.visualization import ZScaleInterval, ImageNormalize\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "# load all FITS files to use, and sort them out with the CCD numbers.\n",
    "\n",
    "ch = \"05\"\n",
    "lst = glob(f'allChips/*{ch}.fits')\n",
    "lst.sort()\n",
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create coordinates that are the centres of sub-images. These coordinates create a grid. \n",
    "sx = 2048\n",
    "sy = 4612\n",
    "dx = 64\n",
    "dy = 64\n",
    "n_border = 16\n",
    "\n",
    "# Define the limits of centre positions\n",
    "x_min, x_max = dx//2 + n_border, sx - (dx//2 + n_border)\n",
    "y_min, y_max = dy//2 + n_border, sy - (dy//2 + n_border)\n",
    "\n",
    "coor_x = np.arange(start=x_min, stop=x_max, step=63)\n",
    "coor_y = np.arange(start=y_min, stop=y_max, step=63)\n",
    "\n",
    "# Combine x, y coordinates into 2D positions\n",
    "coor_ = np.array(np.meshgrid(coor_x, coor_y, indexing='ij')).T.reshape(-1, 2)\n",
    "np.random.shuffle(coor_)\n",
    "len_coor_= len(coor_)\n",
    "\n",
    "# Create indices for image pairs\n",
    "pairs = list(combinations(range(len(lst)), 2))\n",
    "pairs = np.array(pairs)\n",
    "np.random.shuffle(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized coordinates can be used to make the training sets instead.\n",
    "\n",
    "n_samples = 500\n",
    "coor_x_rand = np.random.randint(0, x_max, n_samples)\n",
    "coor_y_rand = np.random.randint(y_min, y_max, n_samples)\n",
    "\n",
    "# Combine x, y coordinates into 2D positions\n",
    "rand_coor = np.column_stack((coor_x_rand, coor_y_rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the head and translate coor_ into the sky coordinates\n",
    "\n",
    "hdu0 = fits.open(lst[0])[1]  \n",
    "wcs0 = WCS(hdu0.header) \n",
    "coor_w0 = wcs0.wcs_pix2world(coor_,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 = Id, \n",
    "1 = x, \n",
    "2 = y, \n",
    "3 = rate of motion in */hr, \n",
    "4 = angle of motion on the sky,\n",
    "5 = rate in RA, \n",
    "6 = rate in Dec, \n",
    "7 = mag, \n",
    "8 = flux multiplier to achieve correct apparent magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that makes sub-images, and also extract information of moving objects in the sub-images.\n",
    "\n",
    "def cut_images(coor_w0,lst,n_lst,dx=64,dy=64,n_border=10,overlap=10,sx=2048,sy=4612):\n",
    "    tp=[]\n",
    "    file_ = lst[n_lst]\n",
    "    fits_ = fits.open(file_)\n",
    "    hdu= fits_[1]\n",
    "    data = hdu.data\n",
    "    header=hdu.header\n",
    "    wcs = WCS(hdu.header)\n",
    "    plst_ = file_[:-5]+'.plantListrd'\n",
    "    plst = np.loadtxt(plst_)\n",
    "    plst = np.array(plst)\n",
    "    for ks in range(len(coor_w0)):\n",
    "        n_object=0\n",
    "        p1=[-1]*11\n",
    "        kx,ky=wcs.wcs_world2pix(coor_w0[ks,0], coor_w0[ks,1], 0)\n",
    "        \n",
    "        for k1 in range(len(plst)):\n",
    "            xp=plst[k1,1]#-1 # should be corrected based on Fortan and python :\n",
    "            yp=plst[k1,2]#-1\n",
    "            if ((xp>=kx-dx//2) & (xp<=kx+dx//2) & (yp>=ky-dy//2) & (yp<=ky+dy//2)):\n",
    "                try:\n",
    "                    coor_MO=Cutout2D(data, [kx,ky], [dx,dy]).to_cutout_position((xp, yp))\n",
    "                except:\n",
    "                    coor_MO=[dx//2+(xp-kx),dx//2+(yp-ky)]\n",
    "                coor_object = [coor_MO[0],coor_MO[1],xp,yp,np.float(kx),np.float(ky)]\n",
    "                pl = plst[k1]\n",
    "                n_object +=1\n",
    "                p1 = plst[k1]\n",
    "            if n_object == 0:\n",
    "                coor_object = [-1,-1,-1,-1,np.float(kx),np.float(ky)]\n",
    "                \n",
    "        try:\n",
    "            data_ = np.reshape(Cutout2D(data, [kx,ky], [dx,dy]).data,(dx,dy))\n",
    "            #data_ = np.reshape(Cutout2D(data, [kx,ky], [dx,dy]).data,-1)\n",
    "            tp.append([file_[:-5], data_,n_object,coor_object,p1])\n",
    "        except:\n",
    "            pass\n",
    "    return tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data, headers, and WCS information from FITS files.\n",
    "\n",
    "fits_data = []\n",
    "fits_header = []\n",
    "wcs_list = []\n",
    "for i in lst:\n",
    "    fits_ = fits.open(i)\n",
    "    hdu = fits_[1]\n",
    "    data = hdu.data\n",
    "    fits_data.append(data)\n",
    "    header = hdu.header\n",
    "    fits_header.append(header)\n",
    "    wcs = WCS(hdu.header)\n",
    "    wcs_list.append(wcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make image pairs using the cut_images function.\n",
    "\n",
    "If used in Step 4, adjust this cell to generate sub-images without artificial moving objects.  \n",
    "The cut_images function should also be simplified for images without artificial moving objects.  \n",
    "In that case, no target accompanies the images.\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process\n",
    "\n",
    "n_cuts = len(coor_w0) # the number of cutout images to make\n",
    "n_pairs = len(pairs)\n",
    "t0=time.asctime()\n",
    "print(t0)\n",
    "def cutimage(k):\n",
    "    im_pair = []\n",
    "    im_pair.append(cut_images(coor_w0[0:n_cuts],lst,k[0]))\n",
    "    im_pair.append(cut_images(coor_w0[0:n_cuts],lst,k[1]))\n",
    "    if np.shape(im_pair) == (2, len(coor_w0), 5):\n",
    "        return im_pair\n",
    "    \n",
    "# Utilize multiprocessing\n",
    "with Pool() as p:\n",
    "    result = p.map(cutimage, pairs)\n",
    "\n",
    "imt = np.array(result)\n",
    "t1 = time.asctime()\n",
    "del result\n",
    "\n",
    "print(np.shape(imt))\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove None values from imt (the list of image pairs created)\n",
    "imt = [e for e in imt if e is not None]\n",
    "imt = np.array(imt, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sub-images\n",
    "np.save('imt', imt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the sub-images\n",
    "# imt = np.load('imt.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550410 1471652 89410\n"
     ]
    }
   ],
   "source": [
    "# make sub-image pairs from the sub-images\n",
    "\n",
    "# count the number of sub-images\n",
    "sz_sam,_,sz_img,_= np.shape(imt)\n",
    "\n",
    "n_n=0  # number of negative (pair of ) images\n",
    "n_p=0  # number of positive (pair of ) images\n",
    "n_pp=0  # number of positive (pair of ) images with moire than one moving object in a 64x64 image\n",
    "\n",
    "inp_pp=[] # input positive (with more than 1 object in a 64x64 image). For now, we are not using it.\n",
    "tar_pp=[] # target positive\n",
    "\n",
    "inp_p=[] # input positive\n",
    "inp_n=[] # input negative \n",
    "tar_p=[] # target (positive)\n",
    "tar_n=[] # target (negative)\n",
    "\n",
    "for kz in range(sz_img):\n",
    "    for k1 in range(sz_sam):\n",
    "        if ((imt[k1,0,kz,2]==1) & (imt[k1,1,kz,2]==1)): \n",
    "            inp_p.append([imt[k1,0,kz,1],imt[k1,1,kz,1]])\n",
    "            tar_p.append([1,1,imt[k1,0,kz,3],imt[k1,1,kz,3],imt[k1,0,kz,0],imt[k1,1,kz,0],imt[k1,0,kz,4],imt[k1,1,kz,4]])\n",
    "            n_p +=1\n",
    "        elif ((imt[k1,0,kz,2]==1) & (imt[k1,1,kz,2]==0)):\n",
    "            inp_p.append([imt[k1,0,kz,1],imt[k1,1,kz,1]])\n",
    "            tar_p.append([1,0,imt[k1,0,kz,3],imt[k1,1,kz,3],imt[k1,0,kz,0],imt[k1,1,kz,0],imt[k1,0,kz,4],imt[k1,1,kz,4]])\n",
    "            n_p +=1\n",
    "        elif ((imt[k1,0,kz,2]==0) & (imt[k1,1,kz,2]==1)):\n",
    "            inp_p.append([imt[k1,0,kz,1],imt[k1,1,kz,1]])\n",
    "            tar_p.append([0,1,imt[k1,0,kz,3],imt[k1,1,kz,3],imt[k1,0,kz,0],imt[k1,1,kz,0],imt[k1,0,kz,4],imt[k1,1,kz,4]])\n",
    "            n_p +=1          \n",
    "        elif ((imt[k1,0,kz,2]==0) & (imt[k1,1,kz,2]==0)):\n",
    "            inp_n.append([imt[k1,0,kz,1],imt[k1,1,kz,1]])\n",
    "            tar_n.append([0,0,imt[k1,0,kz,3],imt[k1,1,kz,3],imt[k1,0,kz,0],imt[k1,1,kz,0],imt[k1,0,kz,4],imt[k1,1,kz,4]])\n",
    "            n_n +=1 \n",
    "        else:\n",
    "            n_pp +=1\n",
    "\n",
    "print(n_p, n_n, n_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the training purpose, create a balanced training set.\n",
    "\n",
    "# Determine the smaller length\n",
    "min_len = min(len(inp_p), len(inp_n))\n",
    "\n",
    "# Create balanced training sets\n",
    "inp_tr = np.array(inp_p[:min_len] + inp_n[:min_len])\n",
    "tar_tr = np.array(tar_p[:min_len] + tar_n[:min_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training or testing set.\n",
    "\n",
    "np.save('Data_sets/'+f'inp_ch{ch}', inp_tr)\n",
    "np.save('Data_sets/'+f'tar_ch{ch}', tar_tr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
